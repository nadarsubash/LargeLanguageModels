{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CacIT0s64Gh3"
      },
      "source": [
        "# INDEX CREATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByYUEk3Mgeoj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bErOFqnMRatg"
      },
      "outputs": [],
      "source": [
        "!pip install openai >aiout.txt\n",
        "!pip install tiktoken >ttout.txt\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E6zBylULwVN"
      },
      "source": [
        "## Reading the Input context file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNKQGLWIMdp4"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(\"texts.csv\", encoding=\"UTF-8\")\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/texts.csv\", encoding=\"unicode_escape\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APUIS8qOMsYb"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKiQooGcL-oh"
      },
      "source": [
        "## Cleaninig the Input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62zR3d4gMwYa"
      },
      "outputs": [],
      "source": [
        "def remove_newlines(serie):\n",
        "  serie = serie.str.replace('</h6>', ' ')\n",
        "  serie = serie.str.replace('®', '')\n",
        "  serie = serie.str.replace('<br>', ' ')\n",
        "  serie = serie.str.replace('<h6>', ' ')\n",
        "  serie = serie.str.replace('•', ' ')\n",
        "  serie = serie.str.replace('\\n', ' ')\n",
        "  serie = serie.str.replace('\\\\n', ' ')\n",
        "  serie = serie.str.replace('  ', ' ')\n",
        "  serie = serie.str.replace('  ', ' ')\n",
        "  serie = serie.str.replace('-',' ')\n",
        "  serie = serie.str.replace('_', ' ')\n",
        "      \n",
        "  return serie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhM9vWcrNdLN"
      },
      "outputs": [],
      "source": [
        "# Set the text column to be the raw text with the newlines removed\n",
        "# df['text'] = df.fname + \". \" + remove_newlines(df.text)\n",
        "df['text'] = remove_newlines(df.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count the OpenAI Tokens for each text"
      ],
      "metadata": {
        "id": "h3AOYhUzpnJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NupsUDK_ooGf"
      },
      "outputs": [],
      "source": [
        "# Load the cl100k_base tokenizer which is designed to work with the ada-002 model\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# Tokenize the text and save the number of tokens to a new column\n",
        "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AETfXEMv8DAd"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCDfDrfLR0kk"
      },
      "source": [
        "## Creating the embedding using the model 'text-embedding-ada-002' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_I62VcAKRggO"
      },
      "outputs": [],
      "source": [
        "openai.api_key =\"\" #OpenAI API Key\n",
        "\n",
        "model=\"text-embedding-ada-002\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2prZ2x_LRkhQ"
      },
      "outputs": [],
      "source": [
        "df['embeddings'] = df['text'].apply(lambda x: openai.Embedding.create(input=x, engine=\"text-embedding-ada-002\")['data'][0]['embedding'])\n",
        "df.to_csv('/content/drive/MyDrive/embeddings.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYosJACcSc15"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}